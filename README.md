üè† Experimento de Regress√£o - House Prices

Este reposit√≥rio cont√©m um experimento de Aprendizado de M√°quina aplicado ao conjunto de dados Ames Housing Dataset, com o objetivo de prever o pre√ßo de im√≥veis a partir de suas caracter√≠sticas.

------------------------------------------------------------
üéØ Objetivo

Avaliar e comparar o desempenho de diferentes algoritmos de regress√£o na tarefa de predi√ß√£o de pre√ßos de im√≥veis. 
O experimento busca identificar o modelo que oferece o melhor equil√≠brio entre erro e capacidade preditiva.

------------------------------------------------------------
üì¶ Dataset

‚Ä¢ Fonte: Kaggle ‚Äì Ames Housing Dataset
‚Ä¢ Tamanho: ~500 amostras  
‚Ä¢ Descri√ß√£o: Inclui vari√°veis como √°rea constru√≠da, n√∫mero de quartos, banheiros, localiza√ß√£o, entre outras.  
‚Ä¢ Vari√°vel alvo: Pre√ßo de venda

------------------------------------------------------------
‚öôÔ∏è Modelos testados

Modelo               | RMSE          | MAE           | R¬≤
----------------------|---------------|---------------|---------
Linear Regression     | 8.48e+08      | 15711.5       | 0.894
Ridge                 | 8.27e+08      | 16158.6       | 0.897
Lasso                 | 8.41e+08      | 15674.4       | 0.895
Random Forest         | 7.11e+08      | 15906.5       | 0.911
XGBoost               | 6.85e+08      | 15534.9       | 0.914
Random Forest (Optuna)| 7.22e+08      | 15831.6       | 0.910
XGBoost (Optuna)      | 6.06e+08      | 13766.8       | 0.924

------------------------------------------------------------
üîç Conclus√µes iniciais

‚Ä¢ O XGBoost tunado apresentou o melhor desempenho geral, alcan√ßando o maior valor de R¬≤ (0.924) e o menor erro (RMSE e MAE).  
‚Ä¢ Modelos lineares (Ridge e Lasso) apresentaram resultados consistentes, mas inferiores aos modelos baseados em √°rvores.  
‚Ä¢ O Random Forest tamb√©m se destacou, com desempenho pr√≥ximo ao do XGBoost.

------------------------------------------------------------
üß™ Tuning e otimiza√ß√£o

Foi utilizada a biblioteca Optuna para otimiza√ß√£o de hiperpar√¢metros, com foco em maximizar o R¬≤ e reduzir o RMSE.  
O experimento pode ser facilmente reproduzido ajustando os par√¢metros no notebook principal:

    experimento_house_prices.ipynb

------------------------------------------------------------
üß∞ Tecnologias utilizadas

‚Ä¢ Python 3  
‚Ä¢ Pandas, NumPy  
‚Ä¢ Scikit-Learn  
‚Ä¢ XGBoost  
‚Ä¢ Optuna  
‚Ä¢ Matplotlib / Seaborn  

------------------------------------------------------------
üöÄ Execu√ß√£o

1. Clone o reposit√≥rio:
```bash
   git clone https://github.com/franciscocolatino/house-prices-ml-experimento.git
   cd house-prices-ml-experimento
```

2. Instale as depend√™ncias:
```bash
   pip install -r requirements.txt
```

3. Execute o notebook no Jupyter ou Google Colab:
```bash
   experimento_house_prices.ipynb
```

------------------------------------------------------------
‚úçÔ∏è Autores

Anderson Passos  
Francisco Colatino  
J√¥natas Duarte  

------------------------------------------------------------
Universidade Federal de Alagoas ‚Äî 2025  
Disciplina: Planejamento de Experimentos
